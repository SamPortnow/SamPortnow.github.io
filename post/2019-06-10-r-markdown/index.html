<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Stanford NLP Tips - </title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Sam Portnow" /><meta name="description" content="Tips on Standford NLP There are several pacakges in R that use the Stanford CoreNLP Software (e.g. cleanNLP, coreNLP). These packages are great for using CoreNLP, but for large projects they are slowww. For a recent project, I had to employ Named Enity Recognition on hundreds of thousands of document, and the aforementioned wrappers around Stanford CoreNLP were just too slow. What significantly sped things up was using the Stanford CoreNLP Software from the command line." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.50 with even 4.0.0" />


<link rel="canonical" href="/post/2019-06-10-r-markdown/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Stanford NLP Tips" />
<meta property="og:description" content="Tips on Standford NLP There are several pacakges in R that use the Stanford CoreNLP Software (e.g. cleanNLP, coreNLP). These packages are great for using CoreNLP, but for large projects they are slowww. For a recent project, I had to employ Named Enity Recognition on hundreds of thousands of document, and the aforementioned wrappers around Stanford CoreNLP were just too slow. What significantly sped things up was using the Stanford CoreNLP Software from the command line." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2019-06-10-r-markdown/" /><meta property="article:published_time" content="2019-06-10T21:13:14-05:00"/>
<meta property="article:modified_time" content="2019-06-10T21:13:14-05:00"/>

<meta itemprop="name" content="Stanford NLP Tips">
<meta itemprop="description" content="Tips on Standford NLP There are several pacakges in R that use the Stanford CoreNLP Software (e.g. cleanNLP, coreNLP). These packages are great for using CoreNLP, but for large projects they are slowww. For a recent project, I had to employ Named Enity Recognition on hundreds of thousands of document, and the aforementioned wrappers around Stanford CoreNLP were just too slow. What significantly sped things up was using the Stanford CoreNLP Software from the command line.">


<meta itemprop="datePublished" content="2019-06-10T21:13:14-05:00" />
<meta itemprop="dateModified" content="2019-06-10T21:13:14-05:00" />
<meta itemprop="wordCount" content="281">



<meta itemprop="keywords" content="NLP," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Stanford NLP Tips"/>
<meta name="twitter:description" content="Tips on Standford NLP There are several pacakges in R that use the Stanford CoreNLP Software (e.g. cleanNLP, coreNLP). These packages are great for using CoreNLP, but for large projects they are slowww. For a recent project, I had to employ Named Enity Recognition on hundreds of thousands of document, and the aforementioned wrappers around Stanford CoreNLP were just too slow. What significantly sped things up was using the Stanford CoreNLP Software from the command line."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo"></a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo"></a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Stanford NLP Tips</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-06-10 </span>
        <div class="post-category">
            <a href="/categories/r/"> R </a>
            </div>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    
  </div>
</div>
    <div class="post-content">
      


<div id="tips-on-standford-nlp" class="section level1">
<h1>Tips on Standford NLP</h1>
<p>There are several pacakges in R that use the <a href="https://stanfordnlp.github.io/CoreNLP/">Stanford CoreNLP Software</a> (e.g. <a href="https://cran.r-project.org/web/packages/cleanNLP/index.html">cleanNLP</a>, <a href="https://cran.r-project.org/web/packages/coreNLP/">coreNLP</a>). These packages are great for using CoreNLP, but for large projects they are <em>slowww</em>. For a recent project, I had to employ Named Enity Recognition on hundreds of thousands of document, and the aforementioned wrappers around Stanford CoreNLP were just too slow. What <em>significantly</em> sped things up was using the Stanford CoreNLP Software from the command line. With RMarkdown, I was able to do it all within RStudio. I also learned some helpful tips along the way.</p>
<p>The first step is to <a href="https://stanfordnlp.github.io/CoreNLP/download.html">download CoreNLP</a>. After it’s downloaded, set up a txt file that lists all of the files, separated by newlines that you want to annotate. And then, run Core NLP over all of them. The best thing about running from the terminal is I can specify the number of threads. I’m running 30 here.</p>
<pre class="bash"><code>cd ~/stanford-corenlp-full-2018-10-05

java -cp &quot;*&quot; edu.stanford.nlp.pipeline.StanfordCoreNLP -filelist $agency_file -annotators &quot;tokenize,ssplit,pos,lemma,ner&quot; -threads 30 -outputFormat &quot;json&quot; -outputDirectory $dir</code></pre>
<p>You can also parallelize Core NLP further, by specifying nthreads. With this specification, the parser can work on multiple sentences at once. However, when I experimented with this, I didn’t have great results with Named Entity Recognition.</p>
<p>The other useful tip is to split long documents into single page documents. From the <a href="https://stanfordnlp.github.io/CoreNLP/memory-time.html">CoreNLP Memory and Time Usage page</a>:</p>
<blockquote>
<p>A whole “document” is represented in memory while processing it. Therefore, if you have a large file, like a novel, the next secret to reducing memory usage is to not treat the whole file as a “document”. Process a large file a piece, say a chapter, at a time, not all at once.</p>
</blockquote>
</div>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Sam Portnow</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2019-06-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/nlp/">NLP</a>
          </div>
      <nav class="post-nav">
        
        <a class="next" href="/post/2019-06-01-r-rmarkdown/">
            <span class="next-text nav-default">IRT From Scratch</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:sam.portnow@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://stackoverflow.com/users/1708405/sam" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://www.linkedin.com/in/sam-portnow-5a46992b/" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://github.com/SamPortnow" class="iconfont icon-github" title="github"></a>
      <a href="https://gitlab.com/SamPortnow" class="iconfont icon-gitlab" title="gitlab"></a>
  <a href="/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">olOwOlo</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
